{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c61bf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7efcc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "def set_random_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_random_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "03488d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the image datasets\n",
    "data_path = 'C:/Users/ashiv/Downloads/3 icon predication and count/train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9007c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image dimensions and other parameters\n",
    "image_width, image_height = 224, 224\n",
    "batch_size = 32\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c05394d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 images belonging to 7 classes.\n",
      "Found 16 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use the ImageDataGenerator to preprocess the images and generate batches of data\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1  # Change the size of the validation dataset here.\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a861329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the pretrained mobile net model to finetune it for our dataset.\n",
    "base_model = MobileNet(include_top=False, input_shape=(image_width, image_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dde0e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the output nodes to fit for only 7 classes that we have.\n",
    "# i.e [bar, cherry, rhino, clown, 7, grape, bell]\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad0d3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "58f84731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.1268 - val_accuracy: 0.5000\n",
      "Epoch 2/7\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.5001 - val_accuracy: 0.5625\n",
      "Epoch 3/7\n",
      "6/6 [==============================] - 12s 2s/step - loss: 4.8497e-04 - accuracy: 1.0000 - val_loss: 4.1276 - val_accuracy: 0.5625\n",
      "Epoch 4/7\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0664 - accuracy: 0.9885 - val_loss: 1.0156 - val_accuracy: 0.8750\n",
      "Epoch 5/7\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.2703 - accuracy: 0.9598 - val_loss: 10.8508 - val_accuracy: 0.4375\n",
      "Epoch 6/7\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0355 - accuracy: 0.9770 - val_loss: 8.5931 - val_accuracy: 0.4375\n",
      "Epoch 7/7\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 2.1469 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260118f5270>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 7\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28ce7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29bc7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Loading the Trained Model\n",
    "loaded_model = tf.keras.models.load_model(\"model.h5\")\n",
    "print(\"Trained model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bb903493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the test image\n",
    "image_path = 'C:/Users/ashiv/Downloads/3 icon predication and count/train_data/clown/P-1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d05af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the test image\n",
    "test_image = image.load_img(image_path, target_size=(image_width, image_height))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0  # Normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2983b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = loaded_model.predict(test_image)\n",
    "class_names = train_generator.class_indices\n",
    "predicted_class = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fc2d50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the predicted class index to class names\n",
    "for key, value in class_names.items():\n",
    "    if value == predicted_class:\n",
    "        predicted_class_name = key\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "95d681a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: clown\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "15d91571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 28). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ashiv\\AppData\\Local\\Temp\\tmpbexglvf3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ashiv\\AppData\\Local\\Temp\\tmpbexglvf3\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7aac4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite model\n",
    "tflite_model_path = 'model.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e3ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
